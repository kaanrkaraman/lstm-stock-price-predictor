{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4861155,"sourceType":"datasetVersion","datasetId":1125174}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kurulum ve Datasetin Oluşturulması","metadata":{}},{"cell_type":"markdown","source":"### Kütüphaneler\n\nKullanılan kütüphaneler import edilmiş ve random fonksiyonları seedlenmiştir.","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport wandb\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom kaggle_secrets import UserSecretsClient\nfrom datetime import datetime, timedelta\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Farklı değişkenlerle eğittiğimiz modellerin takibini yapabilmek için WanDb'ye kayıt oluyoruz.","metadata":{}},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nwandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\nos.environ[\"WANDB_API_KEY\"] = wandb_api_key\nwandb.login(relogin=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Her hisse senedinin hareketleri kendine özgü olduğundan genel bir model eğitmek yerine her hisse senedi için ayrı bir model eğitmeye karar verdik. Burada seçtiğimiz senet için açılış fiyatı ve ticaret hacmi gibi kullanmayacağımız özellikleri filtreliyoruz.","metadata":{}},{"cell_type":"code","source":"ticker = \"MSFT\"\nfile_path = f\"/kaggle/input/stock-market-data/stock_market_data/nasdaq/csv/{ticker}.csv\"\n\ndf = pd.read_csv(file_path, usecols=[\"Date\", \"Close\"])\nscaler = MinMaxScaler()\ndf[\"Close\"] = scaler.fit_transform(df[[\"Close\"]])\n\nprint(df)\n\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d-%m-%Y\", errors=\"coerce\")\ndf.dropna(subset=[\"Date\"], inplace=True)\ndf.set_index(\"Date\", inplace=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(df.index, df[\"Close\"], label=f\"{ticker} Kapanış Fiyatı\")\n\nplt.title(f\"{ticker} Kapanış Fiyatı\")\nplt.xlabel(\"Tarih\")\nplt.ylabel(\"Kapanış Fiyatı US$\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Verilerimizi zaman serisi hâline dönüştürüyoruz. Bu fonksiyon internette bulunabileceği için tekrar yazma gereği duymadık.","metadata":{}},{"cell_type":"code","source":"def df_to_windowed_df(df, start_date, end_date, window_size=3):\n    start_date = pd.to_datetime(start_date, format=\"%d-%m-%Y\")\n    end_date = pd.to_datetime(end_date, format=\"%d-%m-%Y\")\n\n    dates = []\n    X, Y = [], []\n\n    date_range = df.loc[start_date:end_date].index\n\n    for i in range(window_size, len(date_range)):\n        window_dates = date_range[i - window_size:i + 1]\n        window_values = df.loc[window_dates, \"Close\"].values\n\n        if len(window_values) != window_size + 1:\n            continue\n\n        x, y = window_values[:-1], window_values[-1]\n\n        dates.append(window_dates[-1])\n        X.append(x)\n        Y.append(y)\n\n    windowed_df = pd.DataFrame(X, columns=[f\"Target-{i}\" for i in range(window_size, 0, -1)])\n    windowed_df[\"Target\"] = Y\n    windowed_df[\"Target Date\"] = dates\n\n    return windowed_df[[\"Target Date\"] + [f\"Target-{i}\" for i in range(window_size, 0, -1)] + [\"Target\"]]\n\nwindowed_df = df_to_windowed_df(df, \"25-03-2005\", \"23-03-2022\", window_size=21)\nwindowed_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def windowed_df_to_date_X_y(windowed_df):\n    feature_cols = [col for col in windowed_df.columns if col.startswith(\"Target-\")]\n    target_col = \"Target\"\n    date_col = \"Target Date\"\n\n    dates = windowed_df[date_col].to_numpy()\n    X = windowed_df[feature_cols].to_numpy().astype(np.float32).reshape(len(dates), len(feature_cols), 1)\n    y = windowed_df[target_col].to_numpy().astype(np.float32)\n\n    return dates, X, y\n\ndates, X, y = windowed_df_to_date_X_y(windowed_df)\ndates.shape, X.shape, y.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Scikit'teki train test split fonksiyonunu kullanmama sebebimiz verimizin zaman serisi hâlinde olması. Dolayısıyla list slicing ile yaptık.","metadata":{}},{"cell_type":"code","source":"    q_80 = int(len(dates) * .8)\n    q_90 = int(len(dates) * .9)\n    \n    dates_train, X_train, y_train = dates[:q_80], X[:q_80], y[:q_80]\n    dates_val, X_val, y_val = dates[q_80:q_90], X[q_80:q_90], y[q_80:q_90]\n    dates_test, X_test, y_test = dates[q_90:], X[q_90:], y[q_90:]\n    \n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(dates_train, y_train, label=\"Train\")\n    plt.plot(dates_val, y_val, label=\"Val\")\n    plt.plot(dates_test, y_test, label=\"Test\")\n    \n    plt.title(\"Dataset Bölümlemesine Göre Kapanış Fiyatı\")\n    plt.xlabel(\"Tarih\")\n    plt.ylabel(\"Kapanış Fiyati (USD)\")\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelin Oluşturulması ve Eğitimi","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n    device = torch.device(\"mps\")\nelse:\n    device = torch.device(\"cpu\")\n\nprint(\"Kullanılan cihaz:\", device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"LSTM modelimizi oluşturuyoruz. Modelimizin çift yönlü farkındalığa sahip olması bidirectional=True olarak ayarlıyoruz. Mean squared error (MSE) loss fonksiyonunu ve Adam optimizerını kullanacağız. Ayrıca loss fonksiyonun grafiği düzleşmeye başladıkça learning rate'i yani model ağırlıklarının güncellenme hızını azaltmak için ReduceLROnPlateau classını kullanıyoruz.","metadata":{}},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self, input_dim=1, hidden_dim=64, fc_dim=32):\n        super(LSTMModel, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.bidirectional = True\n\n        self.lstm = nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dim,\n            batch_first=True,\n            bidirectional=self.bidirectional\n        )\n\n        lstm_output_dim = hidden_dim * 2 if self.bidirectional else hidden_dim\n\n        self.fc = nn.Sequential(\n            nn.Linear(lstm_output_dim, fc_dim),\n            nn.ReLU(),\n            nn.Linear(fc_dim, 1)\n        )\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)  # (batch, seq, hidden_dim * 2)\n        last_hidden = lstm_out[:, -1, :]\n        return self.fc(last_hidden)\n\nmodel = LSTMModel().to(device)\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode=\"min\", patience=5, factor=0.5\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def to_tensor_dataset(X, y):\n    X_tensor = torch.tensor(X, dtype=torch.float32)\n    y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n    return TensorDataset(X_tensor, y_tensor)\n\ntrain_loader = DataLoader(to_tensor_dataset(X_train, y_train), batch_size=32, shuffle=True)\nval_loader = DataLoader(to_tensor_dataset(X_val, y_val), batch_size=32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Modellerimizin eğitim verilerinin takibi için kullanacağımız Wandb configini ayarlıyoruz.","metadata":{}},{"cell_type":"code","source":"wandb.init(\n    project=\"Hisse Fiyatı Tahminleyicisi\",\n    config={\n        \"model\": \"LSTM\",\n        \"window_size\": 21,\n        \"hidden_dim\": 64,\n        \"fc_dim\": 32,\n        \"batch_size\": 32,\n        \"lr\": 1e-3,\n        \"epochs\": 250,\n        \"patience\": 15,\n    }\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model eğitim döngümüz:","metadata":{}},{"cell_type":"code","source":"best_val_loss = float(\"inf\")\nbest_model_state = None\npatience = 15\nepochs_without_improve = 0\n\nfor epoch in range(1, 251):\n    model.train()\n    train_loss = 0.0\n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n        optimizer.zero_grad()\n        predictions = model(X_batch)\n        loss = criterion(predictions, y_batch)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * X_batch.size(0)\n\n    train_loss /= len(train_loader.dataset)\n\n    model.eval()\n    val_loss = 0.0\n    val_mae = 0.0\n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            predictions = model(X_batch)\n            batch_loss = criterion(predictions, y_batch)\n            val_loss += batch_loss.item() * X_batch.size(0)\n            val_mae += torch.sum(torch.abs(predictions - y_batch)).item()\n\n    val_loss /= len(val_loader.dataset)\n    val_mae /= len(val_loader.dataset)\n    scheduler.step(val_loss)\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_model_state = model.state_dict()\n        torch.save(best_model_state, \"best_model.pth\")\n        epochs_without_improve = 0\n    else:\n        epochs_without_improve += 1\n        if epochs_without_improve == patience:\n            print(f\"Model öğrenmeyi durdurdu, erken durdurma {epoch}. epoch'ta çalıştırıldı.1\")\n            break\n\n    wandb.log({\n        \"epoch\": epoch,\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss,\n        \"val_mae\": val_mae,\n        \"lr\": optimizer.param_groups[0][\"lr\"]\n    })\n\n    if epoch % 10 == 0:\n        print(f\"Epoch {epoch:3d}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}, Val MAE = {val_mae:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Modelimizin ağırlık dosyasını Wandb'ye yüklüyoruz.","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"best_model.pth\"))\nprint(\"Kaydedilen en iyi model yüklendi.\")\n\nartifact = wandb.Artifact(\n    name=ticker,\n    type=\"model\",\n    metadata={\"window_size\": 21, \"bidirectional\": True}\n)\n\nartifact.add_file(\"best_model.pth\")\nwandb.log_artifact(artifact)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelin Değerlendirilmesi","metadata":{}},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n\nwith torch.no_grad():\n    train_preds = model(X_train_tensor).squeeze().cpu().numpy()\n    val_preds = model(X_val_tensor).squeeze().cpu().numpy()\n    test_preds = model(X_test_tensor).squeeze().cpu().numpy()\n\ny_train_real = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\ny_val_real   = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()\ny_test_real  = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n\ntrain_preds_real = scaler.inverse_transform(train_preds.reshape(-1, 1)).flatten()\nval_preds_real   = scaler.inverse_transform(val_preds.reshape(-1, 1)).flatten()\ntest_preds_real  = scaler.inverse_transform(test_preds.reshape(-1, 1)).flatten()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n\nmodel.eval()\nwith torch.no_grad():\n    train_preds = model(X_train_tensor).squeeze().cpu().numpy()\n    \n\nassert len(train_preds) == len(dates_train) == len(y_train)\n\nplt.figure(figsize=(12, 6))\nplt.plot(dates_train, train_preds_real, label=\"Tahmin\")\nplt.plot(dates_train, y_train_real, label=\"GT\")\nplt.xlabel(\"Tarih\")\nplt.ylabel(\"Kapanış Fiyatı US$\")\nplt.title(\"Training Kümesi: GT ve Tahmin\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_predictions(y_true, y_pred, name):\n    mae = mean_absolute_error(y_true, y_pred)\n    print(f\"{name} MAE:  {mae:.4f}\")\n    return mae\n\nevaluate_predictions(y_train_real, train_preds_real, name=\"Train\")\nevaluate_predictions(y_val_real, val_preds_real, name=\"Val\")\ntest_mae = evaluate_predictions(y_test_real, test_preds_real, name=\"Test\")\n\nwandb.log({\n    \"test_mae\": test_mae,\n})\n\nwandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\n\nX_val_tensor_device = X_val_tensor.to(device)\n\nwith torch.no_grad():\n    val_preds = model(X_val_tensor_device).cpu().squeeze().numpy()\n\nplt.figure(figsize=(12, 6))\nplt.plot(dates_val, val_preds_real, label=\"Tahmin\")\nplt.plot(dates_val, y_val_real, label=\"GT\")\nplt.xlabel(\"Tarih\")\nplt.ylabel(\"Kapanış Fiyatı US$\")\nplt.title(\"Validation Kümesi: GT ve Tahmin\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\n\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n\nwith torch.no_grad():\n    test_preds = model(X_test_tensor).cpu().squeeze().numpy()\n\nplt.figure(figsize=(12, 6))\nplt.plot(dates_test, test_preds_real, label=\"Tahmin\")\nplt.plot(dates_test, y_test_real, label=\"GT\")\nplt.xlabel(\"Tarih\")\nplt.ylabel(\"Kapanış Fiyatı US$\")\nplt.title(\"Test Kümesi: GT ve Tahmin\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(14, 7))\n\nplt.plot(dates_train, train_preds, label=\"Train Tahmin\", alpha=0.8)\nplt.plot(dates_train, y_train, label=\"Training GT\", linestyle=\"dashed\", alpha=0.7)\n\nplt.plot(dates_val, val_preds, label=\"Val Tahmin\", alpha=0.8)\nplt.plot(dates_val, y_val, label=\"val GT\", linestyle=\"dashed\", alpha=0.7)\n\nplt.plot(dates_test, test_preds, label=\"Test Tahmin\", alpha=0.8)\nplt.plot(dates_test, y_test, label=\"Testing GT\", linestyle=\"dashed\", alpha=0.7)\n\nplt.xlabel(\"Tarih\")\nplt.ylabel(\"Kapanış Fiyati US$\")\nplt.title(\"Tüm Kümeler Üstünde Tahmin ve GT\")\nplt.legend(ncol=2, fontsize=9)\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def forecast_future_prices(model, df, window_size, scaler, days_ahead=7):\n    model.eval()\n\n    last_window_scaled = df[\"Close\"].values[-window_size:].astype(np.float32).reshape(1, window_size, 1)\n    input_tensor = torch.tensor(last_window_scaled, dtype=torch.float32).to(device)\n\n    predicted_scaled = []\n\n    with torch.no_grad():\n        for _ in range(days_ahead):\n            pred = np.float32(model(input_tensor).cpu().item())\n            predicted_scaled.append(pred)\n\n            new_input = input_tensor.cpu().numpy().squeeze().astype(np.float32)\n            new_input = np.append(new_input[1:], pred).astype(np.float32)\n            input_tensor = torch.tensor(new_input.reshape(1, window_size, 1), dtype=torch.float32).to(device)\n\n    predicted_prices = scaler.inverse_transform(np.array(predicted_scaled).reshape(-1, 1)).flatten()\n    last_date = df.index[-1]\n    future_dates = [last_date + timedelta(days=i+1) for i in range(days_ahead)]\n\n    return future_dates, predicted_prices\n\n\nfuture_dates, future_prices = forecast_future_prices(\n    model=model,\n    df=df,\n    window_size=21,\n    scaler=scaler,\n    days_ahead=7\n)\n\nplt.figure(figsize=(12, 6))\n\nlast_date = df.index[-7]\nlast_price = scaler.inverse_transform(df[[\"Close\"]].values[-1].reshape(1, -1)).item()\nplt.plot([last_date], [last_price], 'bo', label=\"Son Fiyat\")\n\nplt.plot(future_dates, future_prices, label=\"7 Günlük Tahmin\", color='orange')\n\nplt.title(\"7 Günlük Gelecek Kapanış Fiyatı Tahmini\")\nplt.xlabel(\"Tarih\")\nplt.ylabel(\"Kapanış Fiyatı (USD)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}